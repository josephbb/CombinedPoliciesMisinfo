{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0ce757",
   "metadata": {},
   "source": [
    "<h1>Combining Interventions to reduce the spread of misinformation online: Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea9a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install fastparquet\n",
    "!pip install pandarallel\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2843da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Set up environment\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pickle\n",
    "import src.utils as srcu\n",
    "import src.segmentation as srcseg\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import numpy as np\n",
    "#Set up parallel processing\n",
    "pandarallel.initialize(nb_workers=8,\n",
    "                       verbose=True,progress_bar=True,use_memory_fs=None)\n",
    "tqdm.pandas()\n",
    "\n",
    "#Make sure things reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Set up directories\n",
    "root = '.'\n",
    "srcu.create_output_directories(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ad22",
   "metadata": {},
   "source": [
    "<h2>Pull data and segment events</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8b308",
   "metadata": {},
   "source": [
    "<h3>Pull</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5503bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather list of incidents \n",
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/Misc/venus_cred.txt')\n",
    "incidents = sdb.list_incidents(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eca7ba36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidents.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc1b98bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23512/3099402353.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  incidents['incident_name'] = incidents['incident'].apply(fix_name)\n"
     ]
    }
   ],
   "source": [
    "#We need something without spaces and / to call each incident. \n",
    "fix_name = lambda name: name.replace(' ','_').replace('/','_')\n",
    "incidents = incidents[incidents['incident']!='tech: dominion']\n",
    "\n",
    "#Dominion is high volume, very noisy, has daily patterns, is prolonged\n",
    "#and doesn't conform to our notion of \"events\". \n",
    "incidents['incident_name'] = incidents['incident'].apply(fix_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22290d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.to_csv(root + '/data/incidents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff8ce4",
   "metadata": {},
   "source": [
    "<h3>Aggregate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11575a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_csv(root + '/data/incidents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9731e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46027c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4c21baf1624c9b836b9138ba424135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=4), Label(value='0 / 4'))), HBox(câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "425    True\n",
       "426    True\n",
       "427    True\n",
       "428    True\n",
       "429    True\n",
       "Length: 430, dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/Misc/venus_cred.txt')\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine)\n",
    "incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859973c7",
   "metadata": {},
   "source": [
    "<h3>Repeat Offenders</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a67e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = pickle.load(open(root + '/data/removed.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a32a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine()\n",
    "\n",
    "query_ro = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.incident_tweets WHERE user_followers_count > 10000 AND incident IS NOT NULL) AS nested'''\n",
    "\n",
    "query_v = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.incident_tweets \n",
    "            WHERE incident IS NOT NULL AND user_verified) AS nested'''\n",
    "\n",
    "query_all = \"SELECT * FROM incident_tweets LIMIT 10;\"\n",
    "ro_all =pd.read_sql(query_ro, con=engine)\n",
    "ro_verified =pd.read_sql(query_v, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bac0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_all.to_csv(root + '/data/ro_all.csv')\n",
    "ro_verified.to_csv(root + '/data/ro_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030322b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_all = pd.read_csv(root+'/data/ro_all.csv')\n",
    "ro_verified=pd.read_csv(root + '/data/ro_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc8cf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repeat_offenders_dict(df, incidents, follower_thresh=1,strikes=3):\n",
    "    repeat_offenders = {}\n",
    "    for incident in incidents:\n",
    "        temp = df[df['incident']==incident]\n",
    "        temp = temp[temp['row_number'] > strikes]\n",
    "        temp = temp[temp['user_followers_count'] > follower_thresh]\n",
    "        repeat_offenders[incident] = temp['user_screen_name'].unique()\n",
    "    return repeat_offenders\n",
    "\n",
    "ro_dict_10k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=10000)\n",
    "ro_dict_50k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=50000)\n",
    "ro_dict_100k = get_repeat_offenders_dict(ro_all,incidents['incident'], follower_thresh=100000)\n",
    "ro_dict_500k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=500000)\n",
    "ro_dict_v = get_repeat_offenders_dict(ro_verified, incidents['incident'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4219e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_dict_modest = {}\n",
    "for item in ro_dict_100k.keys():\n",
    "    temp = np.unique(np.hstack([ro_dict_100k[item], \n",
    "              ro_dict_v[item],\n",
    "              removed])).tolist()\n",
    "    ro_dict_modest[item] = temp\n",
    "\n",
    "ro_dict_aggressive = {}\n",
    "for item in ro_dict_100k.keys():\n",
    "    temp = np.unique(np.hstack([ro_dict_50k[item], \n",
    "              ro_dict_v[item],\n",
    "              removed])).tolist()\n",
    "    ro_dict_aggressive[item] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6428f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_10k,floc='/data/timeseries/10K/')\n",
    "row = incidents.iloc[45]\n",
    "agg_save(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acc127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_10k,floc='/data/timeseries/10K/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "329f5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_50k,floc='/data/timeseries/50K/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8735ef1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "425    True\n",
       "426    True\n",
       "427    True\n",
       "428    True\n",
       "429    True\n",
       "Length: 430, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_100k,floc='/data/timeseries/100K/',keep=True)\n",
    "incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ba8f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_500k,floc='/data/timeseries/500K/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e113af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_v,floc='/data/timeseries/Verified/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe085928",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=removed,floc='/data/timeseries/currently/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8b450e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_modest,floc='/data/timeseries/modest/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_aggressive,floc='/data/timeseries/aggressive/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee15e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23512/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_23512/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_23512/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_23512/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_23512/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_23512/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_23512/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_23512/780352369.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df=ban_df.append({'Total removed':np.unique(removed).size,\n"
     ]
    }
   ],
   "source": [
    "#Get totals banned by policy\n",
    "ro_dicts = {'10K':ro_dict_10k, \n",
    "             '50K':ro_dict_50k,\n",
    "              '100K':ro_dict_100k, \n",
    "              '500K':ro_dict_500k, \n",
    "                'Verified':ro_dict_v,\n",
    "               'Modest':ro_dict_modest, \n",
    "               'Aggressive':ro_dict_aggressive}\n",
    "ban_df = pd.DataFrame()\n",
    "for policy in ['10K','50K', '100K','500K', 'Verified','Modest','Aggressive']:\n",
    "    N_banned = np.unique(np.hstack([ro_dicts[policy][item] for item in ro_dicts['10K'].keys()])).size\n",
    "    ban_df =ban_df.append({'Total removed':N_banned, \n",
    "                   'Policy':policy},ignore_index=True)\n",
    "ban_df=ban_df.append({'Total removed':np.unique(removed).size, \n",
    "                'Policy':'Currently'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e10235cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_df.to_csv(root + '/data/ban_df_counts.csv',compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dddb7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_csv('./data/incidents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d71d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incident_count(incident,engine):\n",
    "    \"\"\"Return user_followers_count, user_screen_name, created_at, and user_verified \n",
    "     for and incident.\n",
    "    Keyword arguments:\n",
    "    incident -- the name of an incident, as identified in our database\n",
    "    engine -- postgres engine created with src.database.get_engine\n",
    "    \"\"\"\n",
    "    query = \"SELECT  count(*) FROM incident_tweets WHERE incident=(%(incident)s)\"\n",
    "    incident_df = pd.read_sql(query, params={'incident':incident},con=engine)\n",
    "    return incident_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2077cd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0  24617"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = []\n",
    "get_incident_count(incidents['incident'][0], engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afef0031-3325-429e-a8c8-3de8901de686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/Misc/venus_cred.txt')\n",
    "\n",
    "query_ro = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.incident_tweets WHERE incident IS NOT NULL) AS nested'''\n",
    "\n",
    "\n",
    "ro_every_user =pd.read_sql(query_ro, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0a7dfc9-6543-42d2-8ba0-f239ec1d8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/Misc/venus_cred.txt')\n",
    "\n",
    "query_users = '''SSELECT COUNT(*) FROM (SELECT DISTINCT user_id FROM public.incident_tweets) AS temp;'''\n",
    "\n",
    "\n",
    "users_counts =pd.read_sql(query_ro, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c427d36-63af-4a05-ae3c-73cece28f2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>incident</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>___0____</td>\n",
       "      <td>Digital dumps: Michigan 128,000 votes</td>\n",
       "      <td>529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_0_0_</td>\n",
       "      <td>tech: dominion</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000000h00</td>\n",
       "      <td>civil war: general ticket</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000000h00</td>\n",
       "      <td>lost: PA 9 discarded</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000000h00</td>\n",
       "      <td>Physical Mail Mistakes: NYPost Ballot Typo</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672062</th>\n",
       "      <td>Zzzzzzz82592696</td>\n",
       "      <td>voting info: Too Late to Send Mail Ballots</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672063</th>\n",
       "      <td>Zzzzzzz82592696</td>\n",
       "      <td>dead voters: general ticket</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672064</th>\n",
       "      <td>Zzzzzzz82592696</td>\n",
       "      <td>civil war: general ticket</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672065</th>\n",
       "      <td>Zzzzzzz82592696</td>\n",
       "      <td>USPS: 300,000 Undelivered Ballots</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672066</th>\n",
       "      <td>zzzzzzzzzxrrrrr</td>\n",
       "      <td>: maidengate</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10672067 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_screen_name                                    incident  \\\n",
       "0                ___0____       Digital dumps: Michigan 128,000 votes   \n",
       "1                   _0_0_                              tech: dominion   \n",
       "2            000000000h00                   civil war: general ticket   \n",
       "3            000000000h00                        lost: PA 9 discarded   \n",
       "4            000000000h00  Physical Mail Mistakes: NYPost Ballot Typo   \n",
       "...                   ...                                         ...   \n",
       "10672062  Zzzzzzz82592696  voting info: Too Late to Send Mail Ballots   \n",
       "10672063  Zzzzzzz82592696                 dead voters: general ticket   \n",
       "10672064  Zzzzzzz82592696                   civil war: general ticket   \n",
       "10672065  Zzzzzzz82592696           USPS: 300,000 Undelivered Ballots   \n",
       "10672066  zzzzzzzzzxrrrrr                                : maidengate   \n",
       "\n",
       "          user_followers_count  row_number  \n",
       "0                          529           1  \n",
       "1                          326           1  \n",
       "2                            2           1  \n",
       "3                            3           2  \n",
       "4                            4           3  \n",
       "...                        ...         ...  \n",
       "10672062                    56           7  \n",
       "10672063                    57           8  \n",
       "10672064                    59           9  \n",
       "10672065                    59          10  \n",
       "10672066                    87           1  \n",
       "\n",
       "[10672067 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393837f-8c15-46f5-af92-f86914808bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
