{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0ce757",
   "metadata": {},
   "source": [
    "<h1>Combining Interventions to reduce the spread of misinformation online: Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea9a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install fastparquet\n",
    "!pip install pandarallel\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2843da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up environment\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pickle\n",
    "import src.utils as srcu\n",
    "import src.segmentation as srcseg\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import numpy as np\n",
    "#Set up parallel processing\n",
    "pandarallel.initialize(nb_workers=8,\n",
    "                       verbose=True,progress_bar=True,use_memory_fs=None)\n",
    "tqdm.pandas()\n",
    "\n",
    "#Make sure things reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Set up directories\n",
    "root = '.'\n",
    "srcu.create_output_directories(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ad22",
   "metadata": {},
   "source": [
    "<h2>Pull data and segment events</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8b308",
   "metadata": {},
   "source": [
    "<h3>Pull</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather list of incidents \n",
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/Misc/venus_cred.txt')\n",
    "incidents = sdb.list_incidents(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca7ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents\n",
    "\n",
    "incidents['incident'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need something without spaces and / to call each incident. \n",
    "fix_name = lambda name: name.replace(' ','_').replace('/','_')\n",
    "incidents = incidents[incidents['incident']!='tech: dominion']\n",
    "\n",
    "#Dominion is high volume, very noisy, has daily patterns, is prolonged\n",
    "#and doesn't conform to our notion of \"events\". \n",
    "incidents['incident_name'] = incidents['incident'].apply(fix_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22290d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.to_csv(root + '/data/incidents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff8ce4",
   "metadata": {},
   "source": [
    "<h3>Aggregate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11575a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_csv(root + '/data/incidents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46027c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/Misc/venus_cred.txt')\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine)\n",
    "incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859973c7",
   "metadata": {},
   "source": [
    "<h3>Repeat Offenders</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = pickle.load(open(root + '/data/removed.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine()\n",
    "\n",
    "query_ro = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.incident_tweets WHERE user_followers_count > 10000 AND incident IS NOT NULL) AS nested'''\n",
    "\n",
    "query_v = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.incident_tweets \n",
    "            WHERE incident IS NOT NULL AND user_verified) AS nested'''\n",
    "\n",
    "query_all = \"SELECT * FROM incident_tweets LIMIT 10;\"\n",
    "ro_all =pd.read_sql(query_ro, con=engine)\n",
    "ro_verified =pd.read_sql(query_v, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_all.to_csv(root + '/data/ro_all.csv')\n",
    "ro_verified.to_csv(root + '/data/ro_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030322b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_all = pd.read_csv(root+'/data/ro_all.csv')\n",
    "ro_verified=pd.read_csv(root + '/data/ro_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8cf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repeat_offenders_dict(df, incidents, follower_thresh=1,strikes=3):\n",
    "    repeat_offenders = {}\n",
    "    for incident in incidents:\n",
    "        temp = df[df['incident']==incident]\n",
    "        temp = temp[temp['row_number'] > strikes]\n",
    "        temp = temp[temp['user_followers_count'] > follower_thresh]\n",
    "        repeat_offenders[incident] = temp['user_screen_name'].unique()\n",
    "    return repeat_offenders\n",
    "\n",
    "ro_dict_10k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=10000)\n",
    "ro_dict_50k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=50000)\n",
    "ro_dict_100k = get_repeat_offenders_dict(ro_all,incidents['incident'], follower_thresh=100000)\n",
    "ro_dict_500k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=500000)\n",
    "ro_dict_v = get_repeat_offenders_dict(ro_verified, incidents['incident'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4219e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_dict_modest = {}\n",
    "for item in ro_dict_100k.keys():\n",
    "    temp = np.unique(np.hstack([ro_dict_100k[item], \n",
    "              ro_dict_v[item],\n",
    "              removed])).tolist()\n",
    "    ro_dict_modest[item] = temp\n",
    "\n",
    "ro_dict_aggressive = {}\n",
    "for item in ro_dict_100k.keys():\n",
    "    temp = np.unique(np.hstack([ro_dict_50k[item], \n",
    "              ro_dict_v[item],\n",
    "              removed])).tolist()\n",
    "    ro_dict_aggressive[item] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6428f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_10k,floc='/data/timeseries/10K/')\n",
    "row = incidents.iloc[45]\n",
    "agg_save(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_10k,floc='/data/timeseries/10K/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_50k,floc='/data/timeseries/50K/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_100k,floc='/data/timeseries/100K/',keep=True)\n",
    "incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_500k,floc='/data/timeseries/500K/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_v,floc='/data/timeseries/Verified/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe085928",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=removed,floc='/data/timeseries/currently/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b450e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_modest,floc='/data/timeseries/modest/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_aggressive,floc='/data/timeseries/aggressive/',keep=True)\n",
    "_ = incidents.T.apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get totals banned by policy\n",
    "ro_dicts = {'10K':ro_dict_10k, \n",
    "             '50K':ro_dict_50k,\n",
    "              '100K':ro_dict_100k, \n",
    "              '500K':ro_dict_500k, \n",
    "                'Verified':ro_dict_v,\n",
    "               'Modest':ro_dict_modest, \n",
    "               'Aggressive':ro_dict_aggressive}\n",
    "ban_df = pd.DataFrame()\n",
    "for policy in ['10K','50K', '100K','500K', 'Verified','Modest','Aggressive']:\n",
    "    N_banned = np.unique(np.hstack([ro_dicts[policy][item] for item in ro_dicts['10K'].keys()])).size\n",
    "    ban_df =ban_df.append({'Total removed':N_banned, \n",
    "                   'Policy':policy},ignore_index=True)\n",
    "ban_df=ban_df.append({'Total removed':np.unique(removed).size, \n",
    "                'Policy':'Currently'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10235cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_df.to_cs(root + '/data/ban_df_counts.csv',compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_csv('./data/incidents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incident_count(incident,engine):\n",
    "    \"\"\"Return user_followers_count, user_screen_name, created_at, and user_verified \n",
    "     for and incident.\n",
    "    Keyword arguments:\n",
    "    incident -- the name of an incident, as identified in our database\n",
    "    engine -- postgres engine created with src.database.get_engine\n",
    "    \"\"\"\n",
    "    query = \"SELECT  count(*) FROM incident_tweets WHERE incident=(%(incident)s)\"\n",
    "    incident_df = pd.read_sql(query, params={'incident':incident},con=engine)\n",
    "    return incident_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = []\n",
    "get_incident_count(incidents['incident'][0], engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de7d2f-d0fd-4aab-a586-900e8534c3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
