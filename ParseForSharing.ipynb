{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0ce757",
   "metadata": {},
   "source": [
    "<h1>Combining Interventions to reduce the spread of misinformation online: Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea9a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install fastparquet\n",
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2843da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up environment\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pickle\n",
    "import src.utils as srcu\n",
    "import src.segmentation as srcseg\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import numpy as np\n",
    "#Set up parallel processing\n",
    "pandarallel.initialize(nb_workers=8,verbose=True,progress_bar=True)\n",
    "tqdm.pandas()\n",
    "\n",
    "#Make sure things reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Set up directories\n",
    "root = './shared_data'\n",
    "srcu.create_output_directories(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ad22",
   "metadata": {},
   "source": [
    "<h2>Pull data and segment events</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8b308",
   "metadata": {},
   "source": [
    "<h3>Pull</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5503bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather list of incidents \n",
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "incidents = sdb.list_incidents(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1b98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need something without spaces and / to call each incident. \n",
    "fix_name = lambda name: name.replace(' ','_').replace('/','_')\n",
    "incidents = incidents[incidents['incident']!='Dominion1']\n",
    "\n",
    "#Dominion is high volume, very noisy, has daily patterns, is prolonged\n",
    "#and doesn't conform to our notion of \"events\". \n",
    "incidents['incident_name'] = incidents['incident'].apply(fix_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f138cb-d84b-4dc6-9ecd-93db31d60c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident</th>\n",
       "      <th>count</th>\n",
       "      <th>incident_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad_statistics_1</td>\n",
       "      <td>185193</td>\n",
       "      <td>bad_statistics_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad statistics 3</td>\n",
       "      <td>60909</td>\n",
       "      <td>bad_statistics_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad statistics 4</td>\n",
       "      <td>78951</td>\n",
       "      <td>bad_statistics_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad statistics 5</td>\n",
       "      <td>101674</td>\n",
       "      <td>bad_statistics_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad statistics 6</td>\n",
       "      <td>4736</td>\n",
       "      <td>bad_statistics_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           incident   count     incident_name\n",
       "0  bad_statistics_1  185193  bad_statistics_1\n",
       "1  bad statistics 3   60909  bad_statistics_3\n",
       "2  bad statistics 4   78951  bad_statistics_4\n",
       "3  bad statistics 5  101674  bad_statistics_5\n",
       "4  bad statistics 6    4736  bad_statistics_6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22290d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.to_parquet(root + '/data/incidents.parquet', compression=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff8ce4",
   "metadata": {},
   "source": [
    "<h3>Aggregate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11575a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_parquet(root + '/data/incidents.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9731e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46027c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d143e6d81852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m agg_save = lambda row: sdb.aggregate_and_save(row,engine,root=root,\n\u001b[1;32m      4\u001b[0m                                               floc='/data/timeseries/raw/',to_share=True,keep=False)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mincidents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0minput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0moutput_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                 \u001b[0mmap_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             )\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mget_workers_result\u001b[0;34m(use_memory_fs, nb_workers, show_progress_bar, nb_columns, queue, chunk_lengths, input_files, output_files, map_result)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mmessage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mINPUT_FILE_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#RETURN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 64, in global_worker\n",
      "    return _func(x)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 116, in wrapper\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n",
      "    return df.apply(func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 7768, in apply\n",
      "    return op.get_result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 64, in global_worker\n",
      "    return _func(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 64, in global_worker\n",
      "    return _func(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 185, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 116, in wrapper\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 116, in wrapper\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n",
      "    return df.apply(func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n",
      "    return df.apply(func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 7768, in apply\n",
      "    return op.get_result()\n",
      "  File \"<ipython-input-9-d143e6d81852>\", line 4, in <lambda>\n",
      "    floc='/data/timeseries/raw/',to_share=True,keep=False)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 185, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 7768, in apply\n",
      "    return op.get_result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 66, in aggregate_and_save\n",
      "    agg = aggregate(raw_df,freq, removed,to_share)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 185, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 22, in aggregate\n",
      "    fcs = grouped.apply(temp_funct)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"<ipython-input-9-d143e6d81852>\", line 4, in <lambda>\n",
      "    floc='/data/timeseries/raw/',to_share=True,keep=False)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\", line 894, in apply\n",
      "    result = self._python_apply_general(f, self._selected_obj)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 66, in aggregate_and_save\n",
      "    agg = aggregate(raw_df,freq, removed,to_share)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\", line 928, in _python_apply_general\n",
      "    keys, values, mutated = self.grouper.apply(f, data, self.axis)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 22, in aggregate\n",
      "    fcs = grouped.apply(temp_funct)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/ops.py\", line 220, in apply\n",
      "    for key, (i, group) in zip(group_keys, splitter):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\", line 894, in apply\n",
      "    result = self._python_apply_general(f, self._selected_obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/ops.py\", line 980, in __iter__\n",
      "    yield i, self._chop(sdata, slice(start, end))\n",
      "  File \"<ipython-input-9-d143e6d81852>\", line 4, in <lambda>\n",
      "    floc='/data/timeseries/raw/',to_share=True,keep=False)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\", line 928, in _python_apply_general\n",
      "    keys, values, mutated = self.grouper.apply(f, data, self.axis)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/ops.py\", line 1009, in _chop\n",
      "    mgr = sdata._mgr.get_slice(slice_obj, axis=1 - self.axis)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 66, in aggregate_and_save\n",
      "    agg = aggregate(raw_df,freq, removed,to_share)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/ops.py\", line 238, in apply\n",
      "    res = f(group)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 782, in get_slice\n",
      "    new_blocks = [blk.getitem_block(slicer) for blk in self.blocks]\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 21, in <lambda>\n",
      "    temp_funct = lambda x: get_aggregated_follower_counts(x, removed)\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 22, in aggregate\n",
      "    fcs = grouped.apply(temp_funct)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 782, in <listcomp>\n",
      "    new_blocks = [blk.getitem_block(slicer) for blk in self.blocks]\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 9, in get_aggregated_follower_counts\n",
      "    return group[~group['user_screen_name'].isin(removed)]['user_followers_count'].to_list()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\", line 894, in apply\n",
      "    result = self._python_apply_general(f, self._selected_obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 3015, in __getitem__\n",
      "    return self._getitem_bool_array(key)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 338, in getitem_block\n",
      "    if self._validate_ndim and new_values.ndim != self.ndim:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\", line 928, in _python_apply_general\n",
      "    keys, values, mutated = self.grouper.apply(f, data, self.axis)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 3070, in _getitem_bool_array\n",
      "    return self._take_with_is_copy(indexer, axis=0)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/ops.py\", line 238, in apply\n",
      "    res = f(group)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\", line 3600, in _take_with_is_copy\n",
      "    result = self.take(indices=indices, axis=axis)\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 21, in <lambda>\n",
      "    temp_funct = lambda x: get_aggregated_follower_counts(x, removed)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\", line 3587, in take\n",
      "    indices, axis=self._get_block_manager_axis(axis), verify=True\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 9, in get_aggregated_follower_counts\n",
      "    return group[~group['user_screen_name'].isin(removed)]['user_followers_count'].to_list()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1475, in take\n",
      "    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 3015, in __getitem__\n",
      "    return self._getitem_bool_array(key)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1319, in reindex_indexer\n",
      "    for blk in self.blocks\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 3070, in _getitem_bool_array\n",
      "    return self._take_with_is_copy(indexer, axis=0)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1319, in <listcomp>\n",
      "    for blk in self.blocks\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\", line 3600, in _take_with_is_copy\n",
      "    result = self.take(indices=indices, axis=axis)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 64, in global_worker\n",
      "    return _func(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 1881, in take_nd\n",
      "    return self.make_block_same_class(new_values, new_mgr_locs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\", line 3587, in take\n",
      "    indices, axis=self._get_block_manager_axis(axis), verify=True\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 294, in make_block_same_class\n",
      "    return type(self)(values, placement=placement, ndim=ndim)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 116, in wrapper\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 1703, in __init__\n",
      "    super().__init__(values, placement, ndim=ndim)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n",
      "    return df.apply(func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1475, in take\n",
      "    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 137, in __init__\n",
      "    self.ndim = self._check_ndim(values, ndim)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 7768, in apply\n",
      "    return op.get_result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 2443, in _check_ndim\n",
      "    if values.ndim > ndim:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1319, in reindex_indexer\n",
      "    for blk in self.blocks\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 185, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"pandas/_libs/properties.pyx\", line 33, in pandas._libs.properties.CachedProperty.__get__\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/arrays/_mixins.py\", line 110, in ndim\n",
      "    @cache_readonly\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1319, in <listcomp>\n",
      "    for blk in self.blocks\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-9-d143e6d81852>\", line 4, in <lambda>\n",
      "    floc='/data/timeseries/raw/',to_share=True,keep=False)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 1881, in take_nd\n",
      "    return self.make_block_same_class(new_values, new_mgr_locs)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 66, in aggregate_and_save\n",
      "    agg = aggregate(raw_df,freq, removed,to_share)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 294, in make_block_same_class\n",
      "    return type(self)(values, placement=placement, ndim=ndim)\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 22, in aggregate\n",
      "    fcs = grouped.apply(temp_funct)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 1703, in __init__\n",
      "    super().__init__(values, placement, ndim=ndim)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\", line 894, in apply\n",
      "    result = self._python_apply_general(f, self._selected_obj)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 137, in __init__\n",
      "    self.ndim = self._check_ndim(values, ndim)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\", line 928, in _python_apply_general\n",
      "    keys, values, mutated = self.grouper.apply(f, data, self.axis)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 2443, in _check_ndim\n",
      "    if values.ndim > ndim:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/ops.py\", line 238, in apply\n",
      "    res = f(group)\n",
      "  File \"pandas/_libs/properties.pyx\", line 33, in pandas._libs.properties.CachedProperty.__get__\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/arrays/_mixins.py\", line 112, in ndim\n",
      "    return len(self.shape)\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 21, in <lambda>\n",
      "    temp_funct = lambda x: get_aggregated_follower_counts(x, removed)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/joebak/CombinedPolicy/src/segmentation.py\", line 9, in get_aggregated_follower_counts\n",
      "    return group[~group['user_screen_name'].isin(removed)]['user_followers_count'].to_list()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 3015, in __getitem__\n",
      "    return self._getitem_bool_array(key)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 3070, in _getitem_bool_array\n",
      "    return self._take_with_is_copy(indexer, axis=0)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\", line 3600, in _take_with_is_copy\n",
      "    result = self.take(indices=indices, axis=axis)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\", line 3587, in take\n",
      "    indices, axis=self._get_block_manager_axis(axis), verify=True\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1475, in take\n",
      "    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1319, in reindex_indexer\n",
      "    for blk in self.blocks\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1319, in <listcomp>\n",
      "    for blk in self.blocks\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 1396, in take_nd\n",
      "    values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 1757, in take_nd\n",
      "    arr.ndim, arr.dtype, out.dtype, axis=axis, mask_info=mask_info\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 1538, in _get_take_nd_function\n",
      "    tup = (arr_dtype.name, out_dtype.name)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_dtype.py\", line 321, in _name_get\n",
      "    def _name_get(dtype):\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 64, in global_worker\n",
      "    return _func(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 116, in wrapper\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n",
      "    return df.apply(func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 7768, in apply\n",
      "    return op.get_result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 185, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"<ipython-input-9-d143e6d81852>\", line 4, in <lambda>\n",
      "    floc='/data/timeseries/raw/',to_share=True,keep=False)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 63, in aggregate_and_save\n",
      "    raw_df = get_incident_data(row['incident'],engine)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 46, in get_incident_data\n",
      "    incident_df = pd.read_sql(query, params={'incident':incident},con=engine)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 527, in read_sql\n",
      "    chunksize=chunksize,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 1308, in read_query\n",
      "    result = self.execute(*args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 1176, in execute\n",
      "    return self.connectable.execution_options().execute(*args, **kwargs)\n",
      "  File \"<string>\", line 2, in execute\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py\", line 390, in warned\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 3108, in execute\n",
      "    return connection.execute(statement, *multiparams, **params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1252, in execute\n",
      "    future=False,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1553, in _exec_driver_sql\n",
      "    distilled_parameters,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1814, in _execute_context\n",
      "    e, statement, parameters, cursor, context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1998, in _handle_dbapi_exception\n",
      "    util.raise_(exc_info[1], with_traceback=exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n",
      "    raise exception\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1771, in _execute_context\n",
      "    cursor, statement, parameters, context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/default.py\", line 717, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"/opt/conda/lib/python3.7/encodings/utf_8.py\", line 15, in decode\n",
      "    def decode(input, errors='strict'):\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 64, in global_worker\n",
      "    return _func(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 116, in wrapper\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n",
      "    return df.apply(func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 7768, in apply\n",
      "    return op.get_result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 185, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"<ipython-input-9-d143e6d81852>\", line 4, in <lambda>\n",
      "    floc='/data/timeseries/raw/',to_share=True,keep=False)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 63, in aggregate_and_save\n",
      "    raw_df = get_incident_data(row['incident'],engine)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 46, in get_incident_data\n",
      "    incident_df = pd.read_sql(query, params={'incident':incident},con=engine)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 527, in read_sql\n",
      "    chunksize=chunksize,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 1308, in read_query\n",
      "    result = self.execute(*args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 1176, in execute\n",
      "    return self.connectable.execution_options().execute(*args, **kwargs)\n",
      "  File \"<string>\", line 2, in execute\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py\", line 390, in warned\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 3108, in execute\n",
      "    return connection.execute(statement, *multiparams, **params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1252, in execute\n",
      "    future=False,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1553, in _exec_driver_sql\n",
      "    distilled_parameters,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1814, in _execute_context\n",
      "    e, statement, parameters, cursor, context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1998, in _handle_dbapi_exception\n",
      "    util.raise_(exc_info[1], with_traceback=exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n",
      "    raise exception\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1771, in _execute_context\n",
      "    cursor, statement, parameters, context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/default.py\", line 717, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"/opt/conda/lib/python3.7/encodings/utf_8.py\", line 15, in decode\n",
      "    def decode(input, errors='strict'):\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 64, in global_worker\n",
      "    return _func(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 116, in wrapper\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n",
      "    return df.apply(func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 7768, in apply\n",
      "    return op.get_result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 185, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"<ipython-input-9-d143e6d81852>\", line 4, in <lambda>\n",
      "    floc='/data/timeseries/raw/',to_share=True,keep=False)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 63, in aggregate_and_save\n",
      "    raw_df = get_incident_data(row['incident'],engine)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 46, in get_incident_data\n",
      "    incident_df = pd.read_sql(query, params={'incident':incident},con=engine)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 527, in read_sql\n",
      "    chunksize=chunksize,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 1308, in read_query\n",
      "    result = self.execute(*args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 1176, in execute\n",
      "    return self.connectable.execution_options().execute(*args, **kwargs)\n",
      "  File \"<string>\", line 2, in execute\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py\", line 390, in warned\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 3108, in execute\n",
      "    return connection.execute(statement, *multiparams, **params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1252, in execute\n",
      "    future=False,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1553, in _exec_driver_sql\n",
      "    distilled_parameters,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1814, in _execute_context\n",
      "    e, statement, parameters, cursor, context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1998, in _handle_dbapi_exception\n",
      "    util.raise_(exc_info[1], with_traceback=exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n",
      "    raise exception\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1771, in _execute_context\n",
      "    cursor, statement, parameters, context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/default.py\", line 717, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"/opt/conda/lib/python3.7/encodings/utf_8.py\", line 15, in decode\n",
      "    def decode(input, errors='strict'):\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 64, in global_worker\n",
      "    return _func(x)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/pandarallel.py\", line 116, in wrapper\n",
      "    **kwargs\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandarallel/data_types/dataframe.py\", line 31, in worker\n",
      "    return df.apply(func, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\", line 7768, in apply\n",
      "    return op.get_result()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 185, in get_result\n",
      "    return self.apply_standard()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 276, in apply_standard\n",
      "    results, res_index = self.apply_series_generator()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\", line 290, in apply_series_generator\n",
      "    results[i] = self.f(v)\n",
      "  File \"<ipython-input-9-d143e6d81852>\", line 4, in <lambda>\n",
      "    floc='/data/timeseries/raw/',to_share=True,keep=False)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 63, in aggregate_and_save\n",
      "    raw_df = get_incident_data(row['incident'],engine)\n",
      "  File \"/home/joebak/CombinedPolicy/src/database.py\", line 46, in get_incident_data\n",
      "    incident_df = pd.read_sql(query, params={'incident':incident},con=engine)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 527, in read_sql\n",
      "    chunksize=chunksize,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 1308, in read_query\n",
      "    result = self.execute(*args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/sql.py\", line 1176, in execute\n",
      "    return self.connectable.execution_options().execute(*args, **kwargs)\n",
      "  File \"<string>\", line 2, in execute\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/util/deprecations.py\", line 390, in warned\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 3108, in execute\n",
      "    return connection.execute(statement, *multiparams, **params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1252, in execute\n",
      "    future=False,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1553, in _exec_driver_sql\n",
      "    distilled_parameters,\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1814, in _execute_context\n",
      "    e, statement, parameters, cursor, context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1998, in _handle_dbapi_exception\n",
      "    util.raise_(exc_info[1], with_traceback=exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n",
      "    raise exception\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/base.py\", line 1771, in _execute_context\n",
      "    cursor, statement, parameters, context\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sqlalchemy/engine/default.py\", line 717, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "  File \"/opt/conda/lib/python3.7/encodings/utf_8.py\", line 15, in decode\n",
      "    def decode(input, errors='strict'):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,root=root,to_share=True,keep=False)\n",
    "incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859973c7",
   "metadata": {},
   "source": [
    "<h3>Repeat Offenders</h3>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a67e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = pickle.load(open('.' + '/data/removed.p','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a32a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine()\n",
    "\n",
    "query_ro = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.all_ticket_tweets WHERE user_followers_count > 10000 AND incident IS NOT NULL) AS nested'''\n",
    "\n",
    "query_v = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.all_ticket_tweets \n",
    "            WHERE incident IS NOT NULL AND user_verified) AS nested'''\n",
    "\n",
    "query_all = \"SELECT * FROM all_ticket_tweets LIMIT 10;\"\n",
    "ro_all =pd.read_sql(query_ro, con=engine)\n",
    "ro_verified =pd.read_sql(query_v, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bac0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do not provide user names, so this data is not directly shared. \n",
    "ro_all.to_csv('.' + '/data/ro_all.csv')\n",
    "ro_verified.to_csv('.' + '/data/ro_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030322b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_all = pd.read_csv('.'+'/data/ro_all.csv')\n",
    "ro_verified=pd.read_csv('.' + '/data/ro_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8cf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repeat_offenders_dict(df, incidents, follower_thresh=1,strikes=3):\n",
    "    repeat_offenders = {}\n",
    "    for incident in incidents:\n",
    "        temp = df[df['incident']==incident]\n",
    "        temp = temp[temp['row_number'] > strikes]\n",
    "        temp = temp[temp['user_followers_count'] > follower_thresh]\n",
    "        repeat_offenders[incident] = temp['user_screen_name'].unique()\n",
    "    return repeat_offenders\n",
    "\n",
    "ro_dict_10k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=10000)\n",
    "ro_dict_50k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=50000)\n",
    "ro_dict_100k = get_repeat_offenders_dict(ro_all,incidents['incident'], follower_thresh=100000)\n",
    "ro_dict_500k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=500000)\n",
    "ro_dict_v = get_repeat_offenders_dict(ro_verified, incidents['incident'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4219e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_dict_modest = {}\n",
    "for item in ro_dict_100k.keys():\n",
    "    temp = np.unique(np.hstack([ro_dict_100k[item], \n",
    "              ro_dict_v[item],\n",
    "              removed])).tolist()\n",
    "    ro_dict_modest[item] = temp\n",
    "\n",
    "ro_dict_aggressive = {}\n",
    "for item in ro_dict_100k.keys():\n",
    "    temp = np.unique(np.hstack([ro_dict_50k[item], \n",
    "              ro_dict_v[item],\n",
    "              removed])).tolist()\n",
    "    ro_dict_aggressive[item] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6428f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.database as sdb\n",
    "import src.segmentation as srcseg\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_10k,root=root,keep=False,\n",
    "                                              floc='/data/timeseries/10K/',to_share=True)\n",
    "row = incidents.iloc[45]\n",
    "agg_save(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_10k,root=root,keep=False,\n",
    "                                              floc='/data/timeseries/10K/',to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329f5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_50k,root=root,\n",
    "                                              floc='/data/timeseries/50K/',to_share=True,keep=False)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8735ef1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "148    True\n",
       "149    True\n",
       "150    True\n",
       "151    True\n",
       "152    True\n",
       "Length: 152, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,root=root,\n",
    "                                              removed=ro_dict_100k,\n",
    "                                              floc='/data/timeseries/100K/',keep=False,\n",
    "                                              to_share=True)\n",
    "incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba8f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_500k,root=root,\n",
    "                                              floc='/data/timeseries/500K/',keep=False,\n",
    "                                             to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e113af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_v,root=root,\n",
    "                                              floc='/data/timeseries/Verified/',\n",
    "                                              keep=False,to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe085928",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=removed,root=root,\n",
    "                                              floc='/data/timeseries/currently/',\n",
    "                                              keep=False,to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8b450e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_modest,root=root,\n",
    "                                              floc='/data/timeseries/modest/',\n",
    "                                              keep=False,to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_aggressive,root=root,\n",
    "                                              floc='/data/timeseries/aggressive/',\n",
    "                                              keep=False,to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee15e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get totals banned by policy\n",
    "ro_dicts = {'10K':ro_dict_10k, \n",
    "             '50K':ro_dict_50k,\n",
    "              '100K':ro_dict_100k, \n",
    "              '500K':ro_dict_500k, \n",
    "                'Verified':ro_dict_v,\n",
    "               'Modest':ro_dict_modest, \n",
    "               'Aggressive':ro_dict_aggressive}\n",
    "ban_df = pd.DataFrame()\n",
    "for policy in ['10K','50K', '100K','500K', 'Verified','Modest','Aggressive']:\n",
    "    N_banned = np.unique(np.hstack([ro_dicts[policy][item] for item in ro_dicts['10K'].keys()])).size\n",
    "    ban_df =ban_df.append({'Total removed':N_banned, \n",
    "                   'Policy':policy},ignore_index=True)\n",
    "ban_df=ban_df.append({'Total removed':np.unique(removed).size, \n",
    "                'Policy':'Currently'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e10235cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_df.to_parquet(root + '/data/ban_df_counts.parquet',compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dddb7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_parquet('./data/incidents.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d71d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incident_count(incident,engine):\n",
    "    \"\"\"Return user_followers_count, user_screen_name, created_at, and user_verified \n",
    "     for and incident.\n",
    "    Keyword arguments:\n",
    "    incident -- the name of an incident, as identified in our database\n",
    "    engine -- postgres engine created with src.database.get_engine\n",
    "    \"\"\"\n",
    "    query = \"SELECT  count(*) FROM all_ticket_tweets WHERE incident=(%(incident)s)\"\n",
    "    incident_df = pd.read_sql(query, params={'incident':incident},con=engine)\n",
    "    return incident_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2077cd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count\n",
       "0  185193"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = []\n",
    "get_incident_count(incidents['incident'][0], engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431f2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf912034-08ac-4f86-9ffc-99b01209d841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
