{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0ce757",
   "metadata": {},
   "source": [
    "<h1>Combining Interventions to reduce the spread of misinformation online: Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea9a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install fastparquet\n",
    "!pip install pandarallel\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2843da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up environment\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pickle\n",
    "import src.utils as srcu\n",
    "import src.segmentation as srcseg\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import numpy as np\n",
    "#Set up parallel processing\n",
    "pandarallel.initialize(nb_workers=8,verbose=True,progress_bar=True)\n",
    "tqdm.pandas()\n",
    "\n",
    "#Make sure things reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Set up directories\n",
    "root = './shared_data'\n",
    "srcu.create_output_directories(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ad22",
   "metadata": {},
   "source": [
    "<h2>Pull data and segment events</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8b308",
   "metadata": {},
   "source": [
    "<h3>Pull</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5503bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather list of incidents \n",
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/Misc/venus_cred.txt')\n",
    "incidents = sdb.list_incidents(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1b98bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need something without spaces and / to call each incident. \n",
    "fix_name = lambda name: name.replace(' ','_').replace('/','_')\n",
    "incidents = incidents[incidents['incident']!='tech: dominion']\n",
    "\n",
    "#Dominion is high volume, very noisy, has daily patterns, is prolonged\n",
    "#and doesn't conform to our notion of \"events\". \n",
    "incidents['incident_name'] = incidents['incident'].apply(fix_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f138cb-d84b-4dc6-9ecd-93db31d60c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident</th>\n",
       "      <th>count</th>\n",
       "      <th>incident_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ballot box: Collecting After Election</td>\n",
       "      <td>24617</td>\n",
       "      <td>ballot_box:_Collecting_After_Election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ballot box: Fire Baldwin Park</td>\n",
       "      <td>3261</td>\n",
       "      <td>ballot_box:_Fire_Baldwin_Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ballot box: Franklin County Police</td>\n",
       "      <td>4624</td>\n",
       "      <td>ballot_box:_Franklin_County_Police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ballot box: MA fire</td>\n",
       "      <td>49</td>\n",
       "      <td>ballot_box:_MA_fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ballot box: Observe Boxes</td>\n",
       "      <td>83</td>\n",
       "      <td>ballot_box:_Observe_Boxes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                incident  count  \\\n",
       "0  ballot box: Collecting After Election  24617   \n",
       "1          ballot box: Fire Baldwin Park   3261   \n",
       "2     ballot box: Franklin County Police   4624   \n",
       "3                    ballot box: MA fire     49   \n",
       "4              ballot box: Observe Boxes     83   \n",
       "\n",
       "                           incident_name  \n",
       "0  ballot_box:_Collecting_After_Election  \n",
       "1          ballot_box:_Fire_Baldwin_Park  \n",
       "2     ballot_box:_Franklin_County_Police  \n",
       "3                    ballot_box:_MA_fire  \n",
       "4              ballot_box:_Observe_Boxes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22290d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.to_csv(root + '/data/incidents.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff8ce4",
   "metadata": {},
   "source": [
    "<h3>Aggregate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11575a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_csv(root + '/data/incidents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9731e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d4c373-6be9-4784-902f-4aeb20bd0939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "425    True\n",
       "426    True\n",
       "427    True\n",
       "428    True\n",
       "429    True\n",
       "Length: 430, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,root=root,to_share=True,keep=False)\n",
    "incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859973c7",
   "metadata": {},
   "source": [
    "<h3>Repeat Offenders</h3>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a67e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = pickle.load(open('.' + '/data/removed.p','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a32a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine()\n",
    "\n",
    "query_ro = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.incident_tweets WHERE user_followers_count > 10000 AND incident IS NOT NULL) AS nested'''\n",
    "\n",
    "query_v = '''SELECT user_screen_name,incident, user_followers_count,row_number() over (partition by user_screen_name order by created_at) \n",
    "            FROM (SELECT DISTINCT ON (user_screen_name, incident) user_screen_name, user_followers_count,\n",
    "            incident, created_at, row_number() over (partition by user_screen_name order by created_at)\n",
    "            FROM public.incident_tweets \n",
    "            WHERE incident IS NOT NULL AND user_verified) AS nested'''\n",
    "\n",
    "query_all = \"SELECT * FROM all_ticket_tweets LIMIT 10;\"\n",
    "ro_all =pd.read_sql(query_ro, con=engine)\n",
    "ro_verified =pd.read_sql(query_v, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bac0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do not provide user names, so this data is not directly shared. \n",
    "ro_all.to_csv('.' + '/data/ro_all.csv')\n",
    "ro_verified.to_csv('.' + '/data/ro_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030322b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_all = pd.read_csv('.'+'/data/ro_all.csv')\n",
    "ro_verified=pd.read_csv('.' + '/data/ro_verified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8cf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repeat_offenders_dict(df, incidents, follower_thresh=1,strikes=3):\n",
    "    repeat_offenders = {}\n",
    "    for incident in incidents:\n",
    "        temp = df[df['incident']==incident]\n",
    "        temp = temp[temp['row_number'] > strikes]\n",
    "        temp = temp[temp['user_followers_count'] > follower_thresh]\n",
    "        repeat_offenders[incident] = temp['user_screen_name'].unique()\n",
    "    return repeat_offenders\n",
    "\n",
    "ro_dict_10k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=10000)\n",
    "ro_dict_50k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=50000)\n",
    "ro_dict_100k = get_repeat_offenders_dict(ro_all,incidents['incident'], follower_thresh=100000)\n",
    "ro_dict_500k = get_repeat_offenders_dict(ro_all, incidents['incident'],follower_thresh=500000)\n",
    "ro_dict_v = get_repeat_offenders_dict(ro_verified, incidents['incident'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4219e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_dict_modest = {}\n",
    "for item in ro_dict_100k.keys():\n",
    "    temp = np.unique(np.hstack([ro_dict_100k[item], \n",
    "              ro_dict_v[item],\n",
    "              removed])).tolist()\n",
    "    ro_dict_modest[item] = temp\n",
    "\n",
    "ro_dict_aggressive = {}\n",
    "for item in ro_dict_100k.keys():\n",
    "    temp = np.unique(np.hstack([ro_dict_50k[item], \n",
    "              ro_dict_v[item],\n",
    "              removed])).tolist()\n",
    "    ro_dict_aggressive[item] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6428f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.database as sdb\n",
    "import src.segmentation as srcseg\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_10k,root=root,keep=False,\n",
    "                                              floc='/data/timeseries/10K/',to_share=True)\n",
    "row = incidents.iloc[45]\n",
    "agg_save(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc127d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.database as sdb\n",
    "engine = sdb.get_engine('/home/joebak/venus_cred.txt')\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_10k,root=root,keep=False,\n",
    "                                              floc='/data/timeseries/10K/',to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "329f5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_50k,root=root,\n",
    "                                              floc='/data/timeseries/50K/',to_share=True,keep=False)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8735ef1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "425    True\n",
       "426    True\n",
       "427    True\n",
       "428    True\n",
       "429    True\n",
       "Length: 430, dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,root=root,\n",
    "                                              removed=ro_dict_100k,\n",
    "                                              floc='/data/timeseries/100K/',keep=False,\n",
    "                                              to_share=True)\n",
    "incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ba8f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_500k,root=root,\n",
    "                                              floc='/data/timeseries/500K/',keep=False,\n",
    "                                             to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e113af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_v,root=root,\n",
    "                                              floc='/data/timeseries/Verified/',\n",
    "                                              keep=False,to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe085928",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=removed,root=root,\n",
    "                                              floc='/data/timeseries/currently/',\n",
    "                                              keep=False,to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8b450e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_modest,root=root,\n",
    "                                              floc='/data/timeseries/modest/',\n",
    "                                              keep=False,to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)\n",
    "agg_save = lambda row: sdb.aggregate_and_save(row,engine,removed=ro_dict_aggressive,root=root,\n",
    "                                              floc='/data/timeseries/aggressive/',\n",
    "                                              keep=False,to_share=True)\n",
    "_ = incidents.T.parallel_apply(agg_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee15e3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_514/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_514/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_514/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_514/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_514/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_514/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_514/780352369.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df =ban_df.append({'Total removed':N_banned,\n",
      "/tmp/ipykernel_514/780352369.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ban_df=ban_df.append({'Total removed':np.unique(removed).size,\n"
     ]
    }
   ],
   "source": [
    "#Get totals banned by policy\n",
    "ro_dicts = {'10K':ro_dict_10k, \n",
    "             '50K':ro_dict_50k,\n",
    "              '100K':ro_dict_100k, \n",
    "              '500K':ro_dict_500k, \n",
    "                'Verified':ro_dict_v,\n",
    "               'Modest':ro_dict_modest, \n",
    "               'Aggressive':ro_dict_aggressive}\n",
    "ban_df = pd.DataFrame()\n",
    "for policy in ['10K','50K', '100K','500K', 'Verified','Modest','Aggressive']:\n",
    "    N_banned = np.unique(np.hstack([ro_dicts[policy][item] for item in ro_dicts['10K'].keys()])).size\n",
    "    ban_df =ban_df.append({'Total removed':N_banned, \n",
    "                   'Policy':policy},ignore_index=True)\n",
    "ban_df=ban_df.append({'Total removed':np.unique(removed).size, \n",
    "                'Policy':'Currently'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e10235cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_df.to_parquet(root + '/data/ban_df_counts.parquet',compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dddb7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_parquet('./data/incidents.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d71d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incident_count(incident,engine):\n",
    "    \"\"\"Return user_followers_count, user_screen_name, created_at, and user_verified \n",
    "     for and incident.\n",
    "    Keyword arguments:\n",
    "    incident -- the name of an incident, as identified in our database\n",
    "    engine -- postgres engine created with src.database.get_engine\n",
    "    \"\"\"\n",
    "    query = \"SELECT  count(*) FROM all_ticket_tweets WHERE incident=(%(incident)s)\"\n",
    "    incident_df = pd.read_sql(query, params={'incident':incident},con=engine)\n",
    "    return incident_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2077cd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0      0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = []\n",
    "get_incident_count(incidents['incident'][0], engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
